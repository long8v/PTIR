{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n",
    "from argparse import ArgumentParser\n",
    "import yaml\n",
    "import sys\n",
    "import json\n",
    "from shutil import copyfile\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pdb\n",
    "from monai.data import DataLoader, DistributedSampler\n",
    "from dataset_scene import build_scene_graph_data\n",
    "from utils import image_graph_collate_scene_graph\n",
    "from trainer import build_trainer\n",
    "from models import build_model\n",
    "from models.matcher_scene import build_matcher\n",
    "from losses import SetCriterion\n",
    "from datasets.sparse_targets import FrequencyBias\n",
    "from inference import graph_infer\n",
    "# %matplotlib widget\n",
    "sys.path.append(\"..\")\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from scipy import ndimage\n",
    "from scipy.sparse import csr_matrix\n",
    "import box_ops_2D as box_ops\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import text, patheffects\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.gridspec as gridspec\n",
    "import networkx as nx\n",
    "from util.sg_recall import BasicSceneGraphEvaluator\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/visual_genome/obj_count.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'rb') as f:\n",
    "    weight = np.array(pickle.load(f)).T\n",
    "sorted_weight = weight[np.argsort(np.int16(weight[:, 1]))]\n",
    "cls_weight = np.float32(sorted_weight[:,2])/62723.0\n",
    "eps = np.expand_dims(np.array(300-np.sum(cls_weight)), 0)\n",
    "cls_weight = np.concatenate([eps, cls_weight], 0)\n",
    "cls_weight = 1.0/cls_weight\n",
    "cls_weight = 300.0*cls_weight/cls_weight.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = sorted_weight[:,:2][:,[1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {np.int(e[0]):e[1] for e in class_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class obj:\n",
    "    def __init__(self, dict1):\n",
    "        self.__dict__.update(dict1)\n",
    "        \n",
    "def dict2obj(dict1):\n",
    "    return json.loads(json.dumps(dict1), object_hook=obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"./configs/scene_2d.yaml\"\n",
    "with open(config_file) as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "config = dict2obj(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_2_pred = json.load(open(config.DATA.LABEL_DATA_DIR))['idx_to_predicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def plot_coco_sample(image, bboxes, labels, rel, relative_coords=True):\n",
    "    image = np.clip(image*std+mean, 0, 1)\n",
    "    H, W = image.shape[0], image.shape[1]\n",
    "    fig, ax = plt.subplots(figsize=(12,5), dpi=150)\n",
    "    gridspec.GridSpec(1,5)\n",
    "    ax = plt.subplot2grid((1,5), (0,0), colspan=2, rowspan=1)\n",
    "\n",
    "    # Displaying the image\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Bounding boxes\n",
    "    for idx, (bbox, label) in enumerate(zip(bboxes, labels)):\n",
    "        l, t, r, b = bbox * [W, H, W, H] if relative_coords else bbox\n",
    "        rect = patches.Rectangle((l, t), width=(r - l), height=(b - t),\n",
    "                                 linewidth=1, edgecolor='#76b900', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(l,(t-H*0.05), class_dict[label], verticalalignment='top', color='white',fontsize=10,weight='bold').set_path_effects([patheffects.Stroke(linewidth=4, foreground='black'), patheffects.Normal()])\n",
    "    \n",
    "    ax = plt.subplot2grid((1,5), (0,2), colspan=3, rowspan=1)\n",
    "    G = nx.DiGraph()\n",
    "    edges = [tuple(rel[:2]) for rel in rel]\n",
    "    nodes = list(np.unique(np.array(edges)))\n",
    "    labeldict = {}\n",
    "    tmp = [labeldict.update({i: class_dict[l]}) for i, l in zip(nodes, labels[nodes])]\n",
    "    coord_dict = {}\n",
    "    tmp = [coord_dict.update({i:(H*(box[0]+box[2])/2.0, W-W*(box[1]+box[3])/2.0)}) for i,box in enumerate(bboxes)]\n",
    "    edge_labeldict = {}\n",
    "    tmp = [edge_labeldict.update({edges[i]: ind_2_pred[str(l[2])]}) for i,l in enumerate(rel)]\n",
    "\n",
    "    G.add_nodes_from(nodes)\n",
    "    #for n, p in coord_dict.items():\n",
    "    #    G.nodes[n]['pos'] = p\n",
    "    G.add_edges_from(edges)\n",
    "    #pos = nx.get_node_attributes(G,'pos')\n",
    "    #pos = nx.rescale_layout_dict(pos)\n",
    "    pos = nx.circular_layout(G)\n",
    "    nx.draw(G, pos, ax=ax, labels=labeldict, node_size=[len(i[1])**2 * 60 for i in labeldict.items()], node_color='lightcoral', edge_color='mediumorchid', width=1.5, font_size=12, with_labels=True)\n",
    "    nx.draw_networkx_edge_labels(G, pos, ax=ax, edge_labels=edge_labeldict, font_size=12, label_pos=0.5, rotate=False)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def plot_val_sample(image, bboxes1, bboxes2, labels1, labels2, relative_coords=True):\n",
    "    image = np.clip(image*std+mean, 0, 1)\n",
    "    H, W = image.shape[0], image.shape[1]\n",
    "    fig, ax = plt.subplots(1,2,dpi=150)\n",
    "\n",
    "    # Displaying the image\n",
    "    ax[0].imshow(image)\n",
    "    ax[1].imshow(image)\n",
    "\n",
    "    # Bounding boxes\n",
    "    for idx, (bbox, label1) in enumerate(zip(bboxes1, labels1)):\n",
    "        l, t, r, b = bbox * [W, H, W, H] if relative_coords else bbox\n",
    "        rect = patches.Rectangle((l, t), width=(r - l), height=(b - t),\n",
    "                                 linewidth=1, edgecolor='#76b900', facecolor='none')\n",
    "        ax[0].add_patch(rect)\n",
    "        ax[0].text(l,(t-H*0.05), class_dict[label1], verticalalignment='top', color='white',fontsize=10,weight='bold').set_path_effects([patheffects.Stroke(linewidth=4, foreground='black'), patheffects.Normal()])\n",
    "    \n",
    "    for idx, (bbox, label2) in enumerate(zip(bboxes2, labels2)):\n",
    "        l, t, r, b = bbox * [W, H, W, H] if relative_coords else bbox\n",
    "        rect = patches.Rectangle((l, t), width=(r - l), height=(b - t),\n",
    "                                 linewidth=1, edgecolor='#76b900', facecolor='none')\n",
    "        ax[1].add_patch(rect)\n",
    "        ax[1].text(l,(t-H*0.05), class_dict[label2], verticalalignment='top', color='white',fontsize=10,weight='bold').set_path_effects([patheffects.Stroke(linewidth=4, foreground='black'), patheffects.Normal()])\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "def plot_val_rel_sample(image, bboxes1, bboxes2, labels1, labels2, rel1, rel2, attn_map=None, relative_coords=True):\n",
    "    image = np.clip(image*std+mean, 0, 1)\n",
    "    H, W = image.shape[0], image.shape[1]\n",
    "    fig, ax = plt.subplots(1,5, figsize=(25,5), dpi=150)\n",
    "\n",
    "    # Displaying the image\n",
    "    ax[0].imshow(image)\n",
    "    ax[1].imshow(image)\n",
    "    ax[0].axis('off')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    # Bounding boxes\n",
    "    for idx, (bbox, label1) in enumerate(zip(bboxes1, labels1)):\n",
    "        l, t, r, b = bbox * [W, H, W, H] if relative_coords else bbox\n",
    "        rect = patches.Rectangle((l, t), width=(r - l), height=(b - t),\n",
    "                                 linewidth=1, edgecolor='#76b900', facecolor='none')\n",
    "        ax[0].add_patch(rect)\n",
    "        ax[0].text(l,(t-H*0.05), class_dict[label1], verticalalignment='top', color='white',fontsize=10,weight='bold').set_path_effects([patheffects.Stroke(linewidth=4, foreground='black'), patheffects.Normal()])\n",
    "    \n",
    "    for idx, (bbox, label2) in enumerate(zip(bboxes2, labels2)):\n",
    "        l, t, r, b = bbox * [W, H, W, H] if relative_coords else bbox\n",
    "        rect = patches.Rectangle((l, t), width=(r - l), height=(b - t),\n",
    "                                 linewidth=1, edgecolor='#76b900', facecolor='none')\n",
    "        ax[1].add_patch(rect)\n",
    "        ax[1].text(l,(t-H*0.05), class_dict[label2], verticalalignment='top', color='white',fontsize=10,weight='bold').set_path_effects([patheffects.Stroke(linewidth=4, foreground='black'), patheffects.Normal()])\n",
    "   \n",
    "    G = nx.DiGraph()\n",
    "    edges = [tuple(rel[:2]) for rel in rel1]\n",
    "    nodes = list(np.unique(np.array(edges)))\n",
    "    labeldict = {}\n",
    "    tmp = [labeldict.update({i: class_dict[l]}) for i, l in zip(nodes, labels1[nodes])]\n",
    "    coord_dict = {}\n",
    "    tmp = [coord_dict.update({i:(H*(box[0]+box[2])/2.0, W-W*(box[1]+box[3])/2.0)}) for i,box in enumerate(bboxes1)]\n",
    "    edge_labeldict = {}\n",
    "    tmp = [edge_labeldict.update({edges[i]: ind_2_pred[str(l[2])]}) for i,l in enumerate(rel1)]\n",
    "    G.add_nodes_from(nodes)\n",
    "    #for n, p in coord_dict.items():\n",
    "    #    G.nodes[n]['pos'] = p\n",
    "    G.add_edges_from(edges)\n",
    "    #pos = nx.get_node_attributes(G,'pos')\n",
    "    #pos = nx.rescale_layout_dict(pos)\n",
    "    pos = nx.circular_layout(G)\n",
    "    nx.draw(G, pos, ax=ax[2], labels=labeldict, node_size=[len(i[1])**2 * 20 for i in labeldict.items()], node_color='lightcoral', edge_color='mediumorchid', width=1, font_size=8, with_labels=True)\n",
    "    nx.draw_networkx_edge_labels(G, pos, ax=ax[2], edge_labels=edge_labeldict, font_size=8, label_pos=0.5, rotate=False)\n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    edges = [tuple(rel[:2]) for rel in rel2]\n",
    "    nodes = list(np.unique(np.array(edges).flatten()))\n",
    "    labeldict = {}\n",
    "    tmp = [labeldict.update({i: class_dict[l]}) for i, l in zip(nodes, labels2[nodes])]\n",
    "    coord_dict = {}\n",
    "    tmp = [coord_dict.update({i:(H*(box[0]+box[2])/2.0, W-W*(box[1]+box[3])/2.0)}) for i,box in enumerate(bboxes2)]\n",
    "    edge_labeldict = {}\n",
    "    tmp = [edge_labeldict.update({edges[i]: ind_2_pred[str(l[2])]}) for i,l in enumerate(rel2)]\n",
    "    G.add_nodes_from(nodes)\n",
    "    #for n, p in coord_dict.items():\n",
    "    #    G.nodes[n]['pos'] = p\n",
    "    G.add_edges_from(edges)\n",
    "    #pos = nx.get_node_attributes(G,'pos')\n",
    "    #pos = nx.rescale_layout_dict(pos)\n",
    "    pos = nx.circular_layout(G)\n",
    "    nx.draw(G, pos, ax=ax[3], labels=labeldict, node_size=[len(i[1])**2 * 20 for i in labeldict.items()], node_color='lightcoral', edge_color='mediumorchid', width=1, font_size=8,with_labels=True)\n",
    "    nx.draw_networkx_edge_labels(G, pos, ax=ax[3], edge_labels=edge_labeldict, font_size=8, label_pos=0.5, rotate=False)\n",
    "    tokens = [class_dict[l] for l in labels2[nodes]]\n",
    "    nodes.append(attn_map.shape[0]-1)\n",
    "    im = ax[4].imshow(attn_map[:,nodes][nodes,:], origin='lower')\n",
    "    tokens.append('[rln]-token')\n",
    "    # Show all ticks and label them with the respective list entries\n",
    "    ax[4].set_xticks(np.arange(len(tokens)))\n",
    "    ax[4].set_yticks(np.arange(len(tokens)))\n",
    "    ax[4].set_xticklabels(tokens)\n",
    "    ax[4].set_yticklabels(tokens)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax[4].get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = build_scene_graph_data(config, mode='split', debug=True)\n",
    "\n",
    "# mn_dataset_loader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=lambda x: tuple([y_.to(device) for y_ in x_] for x_ in image_graph_collate(x)))\n",
    "\n",
    "train_loader = DataLoader(train_ds,\n",
    "                            batch_size=config.DATA.BATCH_SIZE,\n",
    "                            num_workers=config.DATA.NUM_WORKERS,\n",
    "                            collate_fn=image_graph_collate_scene_graph,\n",
    "                            pin_memory=True,\n",
    "                            sampler= None,)\n",
    "val_loader = DataLoader(val_ds,\n",
    "                            batch_size=config.DATA.BATCH_SIZE,\n",
    "                            num_workers=config.DATA.NUM_WORKERS,\n",
    "                            collate_fn=image_graph_collate_scene_graph,\n",
    "                            pin_memory=True,\n",
    "                            sampler= None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_evaluator = BasicSceneGraphEvaluator.all_modes(multiple_preds=False,config=config)#todo replace wd param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "iteration = 0\n",
    "for images, gt_datas in train_loader:\n",
    "#     print(targets[0][\"orig_size\"])\n",
    "    \n",
    "    boxes = [data['boxes'].to(device, non_blocking=False) for data in gt_datas]\n",
    "    labels = gt_datas[0]['labels'].data.cpu().numpy()\n",
    "    boxes_class = [data['labels'].cpu().numpy()-1.0 for data in gt_datas]\n",
    "    boxes_score = [np.ones(data['labels'].shape[0]) for data in gt_datas]\n",
    "    edges = [data['edges'].cpu().numpy() for data in gt_datas]\n",
    "    bbox = box_ops.box_cxcywh_to_xyxy(boxes[0]).data.cpu().numpy()\n",
    "    iteration = iteration+1\n",
    "    \n",
    "    print('Iteration:',iteration)\n",
    "    plot_coco_sample(images[0].permute(1,2,0), bbox, labels, edges[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(config)\n",
    "model = model.to(device)\n",
    "if config.MODEL.DECODER.FREQ_BIAS: # use freq bias\n",
    "    freq_baseline = FrequencyBias(config.DATA.FREQ_BIAS, train_ds)\n",
    "net_wo_dist = model\n",
    "relation_embed = model.relation_embed\n",
    "freq_baseline = freq_baseline.to(device) if config.MODEL.DECODER.FREQ_BIAS else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = './trained_weights/visual_genome_checkpoint.pt'\n",
    "checkpoint = torch.load(ckpt_path, map_location='cpu')\n",
    "missing_keys, unexpected_keys = model.load_state_dict(checkpoint['net'], strict=False)\n",
    "unexpected_keys = [k for k in unexpected_keys if not (k.endswith('total_params') or k.endswith('total_ops'))]\n",
    "if len(missing_keys) > 0:\n",
    "    print('Missing Keys: {}'.format(missing_keys))\n",
    "if len(unexpected_keys) > 0:\n",
    "    print('Unexpected Keys: {}'.format(unexpected_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "iteration = 0\n",
    "for images, gt_datas in val_loader:\n",
    "    images = [image.cuda() for image in images]\n",
    "    print(images[0].shape, images[0].dtype)\n",
    "    boxes = [data['boxes'].to(device, non_blocking=False) for data in gt_datas]\n",
    "    labels1 = gt_datas[0]['labels'].data.cpu().numpy()\n",
    "    boxes_class = [data['labels'].cpu().numpy()-1.0 for data in gt_datas]\n",
    "    boxes_score = [np.ones(data['labels'].shape[0]) for data in gt_datas]\n",
    "    edges1 = [data['edges'].cpu().numpy() for data in gt_datas]\n",
    "    bbox1 = box_ops.box_cxcywh_to_xyxy(boxes[0]).data.cpu().numpy()\n",
    "\n",
    "    model.eval()\n",
    "    h, out1 = model(images)  # todo output logit and edge are same value\n",
    "    relation_embed = model.relation_embed\n",
    "    out = graph_infer(h, out1, relation_embed,  freq=freq_baseline, emb=config.MODEL.DECODER.ADD_EMB_REL)\n",
    "    \n",
    "    pred_edges = [{'node_pair': pred_rels, 'edge_score': edge_score} for pred_rels, edge_score in zip(out['all_node_pairs'], out['all_relation'])]\n",
    "    pred_classes = [{'labels': pred_class+1, 'scores': pred_score, 'boxes': torch.tensor(pred_box)} for pred_class, pred_score, pred_box in zip(out['pred_boxes_class'], out['pred_boxes_score'], out['pred_boxes'])]\n",
    "\n",
    "    for i, (gt_data, pred_class, pred_edge) in enumerate(zip(gt_datas, pred_classes, pred_edges)):\n",
    "        # prepare scene graph evaluation\n",
    "        res = sg_evaluator['sgdet'].evaluate_scene_graph_entry(gt_data,[pred_class, pred_edge],vis=True)\n",
    "        break\n",
    "    \n",
    "    bbox2 = box_ops.box_cxcywh_to_xyxy(torch.tensor(out['pred_boxes'][0]).to(device, non_blocking=False)).data.cpu().numpy()\n",
    "    labels2 = out['pred_boxes_class'][0]+1\n",
    "    \n",
    "    edges2 = np.concatenate([out['pred_rels'][0], out['pred_rels_class'][0]], 1)\n",
    "    node_id = np.append(out['node_id'][0], 200)\n",
    "    rel_filter = np.array([i for i,r in enumerate(res[0]) if r])\n",
    "    # print('ALL OBjects', labels2.shape[0], 'All edges', edges2.shape[0], 'Match', res[1].shape[0], np.int32(res[4]).max())\n",
    "    # edges2 = edges2[np.int32(res[4][:20]),:]\n",
    "    edges2 = edges2[res[4],:] \n",
    "    if rel_filter.any():\n",
    "        edges2 = edges2[rel_filter,:]\n",
    "    else:\n",
    "        edges2 = torch.empty(0,3).numpy()\n",
    "    # print('After Prune', edges2.shape[0])\n",
    "    \n",
    "    atten_map = out1['attn_map'][0].data.cpu().numpy()[0][node_id,:][:,node_id]\n",
    "    plot_val_rel_sample(images[0].permute(1,2,0).cpu().numpy(), bbox1, bbox2, labels1, labels2, edges1[0], edges2, atten_map)\n",
    "    \n",
    "    iteration = iteration+1\n",
    "    print('Iteration:',iteration)\n",
    "    if iteration>5:\n",
    "        break\n",
    "        \n",
    "    # bbox2 = box_ops.box_cxcywh_to_xyxy(torch.tensor(out['pred_boxes'][0]).to(device, non_blocking=False))\n",
    "    # score, labels2 = torch.max(torch.softmax(out['pred_logits'], 2) ,2)\n",
    "    # score = score[0]\n",
    "    # labels2 = labels2[0]\n",
    "    # labels2 = labels2[score>0.6].data.cpu().numpy()\n",
    "    # bbox2 = bbox2[score>0.6].data.cpu().numpy()\n",
    "    # bbox2 = bbox2[labels2>0,:]\n",
    "    # labels2 = labels2[labels2>0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepro",
   "language": "python",
   "name": "deepro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "0a65b42259c001818d23a7dae5036e8364bfc846daa533e50e38f7a76759b9bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
